Demo is not generating nice results, but PSNR from test makes sense.
Using x2
Testing: python test.py --config configs/test/test-div2k-2.yaml --model save/_train_swinir-lte/epoch-best.pth --window 8 --gpu 0 
Training: python train.py --config configs/train-div2k/train_swinir-lte.yaml --gpu 0
If you want to test with the pretrained weights, change the number of heads and their depths, and use the appropriate pth.
We should think about selecting a different learning rate (ask the prof if we should try larger or lower), and perhaps reducing epoch but increasing network size.


Things we changed:
lib to Lib in one directory of anaconda
Number of workers of the data loader from 8 to 1 so that it would fit in the regular ram
Batch size of the inputs at training from 32 to 4 so that it fits into our GPU RAM
Number of repeats of the training and validation datasets to 1 so that training would be faster
Reduced the number of heads and their depths for a smaller model
Using DIV2K: 300 for training, 60 for validation. Number of images shouldn't cause overfitting since it is a generative model. 20-80% is a common ratio for validation.
Using SET14 for testing (PSNR calculation)
